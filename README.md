# Data Visualizer with Local LLM Insights

## Overview

This project is a flexible data exploration and reporting tool. It lets you upload a CSV dataset, automatically analyze it, and generate both interactive charts and a written executive-style summary.

The tool is designed to work across different domains—transportation data, retail sales, survey responses, or any structured dataset. It not only produces standard statistical summaries and plots but also leverages a locally hosted large language model (LLM) to generate narrative insights and potential optimization strategies.

Running the LLM locally avoids the need for paid API calls, making the project fully self-contained and cost-free once set up.

---

## Features

* Automatic dataset profiling, including summary statistics, missing values, correlations, and unique counts.
* Visualizations such as histograms, heatmaps, scatterplots, boxplots, time series charts, and categorical breakdowns.
* A Streamlit web application for uploading datasets and exploring results interactively.
* Executive summaries generated by a local LLM, written in plain English and tailored for business stakeholders.
* No reliance on external APIs, meaning the project can run offline and at no ongoing cost.

---

## Tools and Technologies

* **Python** for data processing and visualization

  * pandas, numpy, matplotlib, seaborn, plotly
* **Streamlit** for the interactive dashboard
* **LM Studio** for hosting local LLMs with an OpenAI-compatible API
* Any compatible LLM model (tested with GPT-OSS 20B)

---

## Why Local LLM

Many data science projects rely on cloud-based APIs to generate insights, which introduces both cost and dependency on external services. This project demonstrates that advanced AI-driven reporting can be run fully on local hardware. This approach is:

* Cost-effective (no API fees)
* Private and offline-capable
* A stronger technical demonstration, since it shows how to integrate LLM inference directly into a workflow

---

## Project Structure

```
datasciencerepo/
├── datavisualizer.py   # Core analysis and visualization logic
├── app.py              # Streamlit dashboard
├── figures/            # Auto-generated charts
├── sample_data/        # Example CSVs
├── requirements.txt    # Python dependencies
├── .env.example        # Example environment variables
└── README.md           # Documentation
```

---

## Quickstart

1. Clone the repository:

   ```bash
   git clone https://github.com/yourusername/datasciencerepo.git
   cd datasciencerepo
   ```

2. Install dependencies:

   ```bash
   pip install -r requirements.txt
   ```

3. Start LM Studio, load a model (for example, `gpt-oss-20b`), and confirm the API is available at `http://127.0.0.1:1234/v1`.

4. Run the dashboard:

   ```bash
   streamlit run app.py
   ```

5. Upload a dataset through the interface and explore the generated charts and AI-written executive summary.

---

## Future Directions

* Add more advanced statistical tools such as regression, forecasting, or clustering.
* Support for Excel files and database connections.
* Industry-specific summary templates (e.g., for retail, healthcare, or transportation).
* Automated PowerPoint or PDF report generation.

---

## License

This project is licensed under the MIT License.

---

